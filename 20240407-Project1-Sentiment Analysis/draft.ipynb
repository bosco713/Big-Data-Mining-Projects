{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'label'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"label\" column is the labels (sentiment). \n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data('train', columns=['text', 'label'], folder='data')\n",
    "valid_df = load_data('valid', columns=['text', 'label'], folder='data')\n",
    "# the test set labels (the 'label' column) are unavailable! So the following code will instead return all columns\n",
    "test_df = load_data('test_no_label', columns=['id', 'text'], folder='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.size)\n",
    "print(valid_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set (stopwords.words('english'))\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "def lower(s):\n",
    "    \"\"\"\n",
    "    :param s: a string.\n",
    "    return a string with lower characters\n",
    "    Note that we allow the input to be nested string of a list.\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: 'text mining is to identify useful information.'\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return [lower(t) for t in s]\n",
    "    if isinstance(s, str):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown datatype\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     results.append(ps.stem(token))\n",
    "    # return results\n",
    "\n",
    "    return [porterStemmer.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     if token not in stopwords and not token.isnumeric():\n",
    "    #         results.append(token)\n",
    "    # return results\n",
    "\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector\n",
    "\n",
    "def biGram(tokens):\n",
    "    return n_gram(tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = train_df['text'].map(tokenize).map(filter_stopwords).map(stem).map(biGram)\n",
    "train_data_y = train_df['label']\n",
    "valid_data_x = valid_df['text'].map(tokenize).map(filter_stopwords).map(stem).map(biGram)\n",
    "valid_data_y = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "for tokens in train_data_x:\n",
    "    for t in tokens:\n",
    "        if not t in word2id:\n",
    "            word2id[t] = len(word2id)\n",
    "word2id['<pad>'] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_id_seq(texts, padding_length=50):\n",
    "    records = []\n",
    "    for tokens in texts:\n",
    "        record = []\n",
    "        for t in tokens:\n",
    "            record.append(word2id.get(t, len(word2id)))\n",
    "        if len(record) >= padding_length:\n",
    "            records.append(record[:padding_length])\n",
    "        else:\n",
    "            records.append(record + [word2id['<pad>']] * (padding_length - len(record)))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = texts_to_id_seq(train_data_x)\n",
    "valid_seqs = texts_to_id_seq(valid_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq, y):\n",
    "        assert len(seq) == len(y)\n",
    "        self.seq = seq\n",
    "        self.y = y-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.seq[idx]), self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(MyDataset(train_seqs, train_data_y), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(MyDataset(valid_seqs, valid_data_y), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(word2id)+1, embedding_dim=64)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=5,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=5, stride=1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear = nn.Linear(16, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.cnn(x)\n",
    "        x = torch.max(x, dim=-1)[0]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, 11):    \n",
    "    print('epoch', e)\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with tqdm.tqdm(train_loader) as t:\n",
    "        for x, y in t:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with tqdm.tqdm(valid_loader) as t:\n",
    "        for x, y in t:\n",
    "            logits = model(x)\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += len(y)\n",
    "            y_pred += logits.argmax(1).tolist()\n",
    "            y_true += y.tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = train_df['text'].map(tokenize).map(filter_stopwords).map(stem)\n",
    "train_data_y = train_df['label']\n",
    "valid_data_x = valid_df['text'].map(tokenize).map(filter_stopwords).map(stem)\n",
    "valid_data_y = valid_df['label']\n",
    "train_seqs = texts_to_id_seq(train_data_x)\n",
    "valid_seqs = texts_to_id_seq(valid_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_9010 = TfidfVectorizer(max_features = 5000)\n",
    "tfidf_vect_9010.fit(train_df)\n",
    "train_X_tfidf_9010 = tfidf_vect_9010.transform(train_df['text'])\n",
    "test_X_tfidf_9010 = tfidf_vect_9010.transform(valid_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(train_X_tfidf_9010, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_X_tfidf_9010)\n",
    "print(classification_report(valid_data_y, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(valid_data_y, y_pred))\n",
    "print('accuracy', np.mean(valid_data_y == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [text, label] columns from the valid split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train')\n",
    "valid_df = load_data('valid')\n",
    "x_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "x_valid = valid_df['text']\n",
    "y_valid = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = train_df['text'].map(tokenize).map(lower).map(filter_stopwords).map(stem)\n",
    "train_data_y = train_df['label']\n",
    "valid_data_x = valid_df['text'].map(tokenize).map(lower).map(filter_stopwords).map(stem)\n",
    "valid_data_y = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n"
     ]
    }
   ],
   "source": [
    "print(train_data_x.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_data_x)):\n",
    "    train_data_x[i] = ' '.join(train_data_x[i])\n",
    "for i in range(len(valid_data_x)):\n",
    "    valid_data_x[i] = ' '.join(valid_data_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x.to_csv(\"data/norm_train_data.csv\")\n",
    "valid_data_x.to_csv(\"data/norm_valid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the norm_train_data split\n",
      "Failed loading specified columns... Returning all columns from the norm_train_data split\n",
      "select [text, label] columns from the norm_valid_data split\n",
      "Failed loading specified columns... Returning all columns from the norm_valid_data split\n"
     ]
    }
   ],
   "source": [
    "norm_train_data = load_data(\"norm_train_data\")['text']\n",
    "norm_valid_data = load_data(\"norm_valid_data\")['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two wolfgang petersen direct film togeth one p...\n",
       "1    fan seri movi film must . continu wrath khan l...\n",
       "2    love movi . blu-ray fine , came expir digit co...\n",
       "3    n't know go end movi . seen movi n't know happ...\n",
       "4    watch minut movi , due offens content . want s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(min_df=0.0, max_df=0.5, binary=False, ngram_range=(1, 3))\n",
    "cV_train = countVectorizer.fit_transform(norm_train_data)\n",
    "cV_valid = countVectorizer.transform(norm_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 328864)\n",
      "(2000, 328864)\n"
     ]
    }
   ],
   "source": [
    "print(cV_train.shape)\n",
    "print(cV_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(cV_train, y_train)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.52      0.54       295\n",
      "           2       0.36      0.19      0.25       198\n",
      "           3       0.47      0.55      0.51       508\n",
      "           4       0.50      0.45      0.47       523\n",
      "           5       0.61      0.71      0.65       476\n",
      "\n",
      "    accuracy                           0.52      2000\n",
      "   macro avg       0.50      0.48      0.48      2000\n",
      "weighted avg       0.51      0.52      0.51      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[153  30  71  19  22]\n",
      " [ 54  37  80  17  10]\n",
      " [ 39  27 281 118  43]\n",
      " [ 17   7 125 235 139]\n",
      " [ 13   3  40  84 336]]\n",
      "accuracy 0.521\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(cV_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(min_df=0.0, max_df=0.9, binary=False, ngram_range=(1, 3))\n",
    "cV_train = countVectorizer.fit_transform(norm_train_data)\n",
    "cV_valid = countVectorizer.transform(norm_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sksvm = svm.NuSVC(kernel='linear', decision_function_shape='ovo')\n",
    "sksvm.fit(cV_train, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sksvm.predict(cV_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth trail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [text, label] columns from the valid split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train')\n",
    "valid_df = load_data('valid')\n",
    "x_train = train_df['text'].map(tokenize).map(lower).map(filter_stopwords).map(stem)\n",
    "y_train = train_df['label']\n",
    "x_valid = valid_df['text'].map(tokenize).map(lower).map(filter_stopwords).map(stem)\n",
    "y_valid = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = ' '.join(x_train[i])\n",
    "for i in range(len(x_valid)):\n",
    "    x_valid[i] = ' '.join(x_valid[i])\n",
    "x_train.to_csv(\"data/norm_train_data.csv\")\n",
    "x_valid.to_csv(\"data/norm_valid_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the norm_train_data split\n",
      "Failed loading specified columns... Returning all columns from the norm_train_data split\n",
      "select [text, label] columns from the norm_valid_data split\n",
      "Failed loading specified columns... Returning all columns from the norm_valid_data split\n"
     ]
    }
   ],
   "source": [
    "norm_train_data = load_data(\"norm_train_data\")['text']\n",
    "norm_valid_data = load_data(\"norm_valid_data\")['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "for tokens in norm_train_data:\n",
    "    for t in tokens:\n",
    "        if not t in word2id:\n",
    "            word2id[t] = len(word2id)\n",
    "word2id['<pad>'] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_id_seq(texts, padding_length=50):\n",
    "    records = []\n",
    "    for tokens in texts:\n",
    "        record = []\n",
    "        for t in tokens:\n",
    "            record.append(word2id.get(t, len(word2id)))\n",
    "        if len(record) >= padding_length:\n",
    "            records.append(record[:padding_length])\n",
    "        else:\n",
    "            records.append(record + [word2id['<pad>']] * (padding_length - len(record)))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = texts_to_id_seq(norm_train_data)\n",
    "valid_seqs = texts_to_id_seq(norm_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(train_seqs)).type(torch.LongTensor)\n",
    "X_valid_tensors = Variable(torch.Tensor(valid_seqs)).type(torch.LongTensor)\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train)).type(torch.LongTensor)\n",
    "y_valid_tensors = Variable(torch.Tensor(y_valid)).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq, y):\n",
    "        assert len(seq) == len(y)\n",
    "        self.seq = seq\n",
    "        self.y = y-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.seq[idx]), self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(MyDataset(X_train_tensors, y_train_tensors), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(MyDataset(X_valid_tensors, y_valid_tensors), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_model(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(lstm_model, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(word2id)+1, embedding_dim=input_size)\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.max = nn.MaxPool1d(kernel_size=3,\n",
    "                                stride=1)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        embedd = self.embedding(x)\n",
    "        embedd = self.drop(embedd)\n",
    "        output, (hn, cn) = self.lstm(embedd, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        # return self.softmax(self.fc(output[:,-1,:]))\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        # out = self.fc_1(out) #first Dense\n",
    "        # out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, input_size, hidden_size, num_layers, seq_length = 5, 64, 128, 1, 1\n",
    "model = lstm_model(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:31<00:00, 36.18it/s, loss=0.0977, acc=0.253]\n",
      "100%|██████████| 125/125 [00:02<00:00, 47.62it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.26      0.52      0.34       508\n",
      "           3       0.24      0.07      0.11       523\n",
      "           4       0.25      0.43      0.32       476\n",
      "\n",
      "    accuracy                           0.25      2000\n",
      "   macro avg       0.15      0.20      0.15      2000\n",
      "weighted avg       0.19      0.25      0.19      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0 152  26 117]\n",
      " [  0   0 109  13  76]\n",
      " [  0   0 262  44 202]\n",
      " [  0   0 253  36 234]\n",
      " [  0   0 241  28 207]]\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:48<00:00, 23.03it/s, loss=0.0973, acc=0.264]\n",
      "100%|██████████| 125/125 [00:02<00:00, 62.21it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.25      0.81      0.39       508\n",
      "           3       0.28      0.10      0.14       523\n",
      "           4       0.29      0.11      0.16       476\n",
      "\n",
      "    accuracy                           0.26      2000\n",
      "   macro avg       0.16      0.20      0.14      2000\n",
      "weighted avg       0.20      0.26      0.17      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0 226  34  35]\n",
      " [  0   0 176  14   8]\n",
      " [  0   0 413  52  43]\n",
      " [  0   0 431  51  41]\n",
      " [  0   0 391  34  51]]\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 43.56it/s, loss=0.0969, acc=0.275]\n",
      "100%|██████████| 125/125 [00:01<00:00, 117.28it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.30      0.51      0.38       508\n",
      "           3       0.26      0.10      0.14       523\n",
      "           4       0.32      0.65      0.43       476\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.18      0.25      0.19      2000\n",
      "weighted avg       0.22      0.31      0.24      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0 169  30  96]\n",
      " [  0   0 117  16  65]\n",
      " [  0   0 257  62 189]\n",
      " [  0   0 181  51 291]\n",
      " [  0   0 130  38 308]]\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 44.92it/s, loss=0.0963, acc=0.287]\n",
      "100%|██████████| 125/125 [00:01<00:00, 112.36it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.30      0.56      0.39       508\n",
      "           3       0.23      0.07      0.11       523\n",
      "           4       0.34      0.63      0.44       476\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.17      0.25      0.19      2000\n",
      "weighted avg       0.22      0.31      0.23      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0 188  20  87]\n",
      " [  0   0 122  13  63]\n",
      " [  0   0 282  55 171]\n",
      " [  0   0 215  39 269]\n",
      " [  0   0 133  41 302]]\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 45.61it/s, loss=0.0935, acc=0.328]\n",
      "100%|██████████| 125/125 [00:01<00:00, 109.32it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.29      0.51      0.37       508\n",
      "           3       0.33      0.47      0.39       523\n",
      "           4       0.50      0.38      0.43       476\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.22      0.27      0.24      2000\n",
      "weighted avg       0.28      0.34      0.30      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  0   0 194  80  21]\n",
      " [  0   0 136  47  15]\n",
      " [  0   0 259 204  45]\n",
      " [  0   0 172 246 105]\n",
      " [  0   0 121 172 183]]\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 43.79it/s, loss=0.0916, acc=0.343]\n",
      "100%|██████████| 125/125 [00:01<00:00, 108.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.08       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.29      0.52      0.37       508\n",
      "           3       0.35      0.38      0.36       523\n",
      "           4       0.45      0.46      0.45       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.30      0.28      0.25      2000\n",
      "weighted avg       0.33      0.35      0.31      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 13   0 208  44  30]\n",
      " [  5   0 140  30  23]\n",
      " [  4   1 264 164  75]\n",
      " [  4   0 177 200 142]\n",
      " [  4   0 117 138 217]]\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:50<00:00, 22.10it/s, loss=0.09, acc=0.365]  \n",
      "100%|██████████| 125/125 [00:02<00:00, 45.93it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.39      0.36       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.33      0.36      0.35       508\n",
      "           3       0.35      0.34      0.34       523\n",
      "           4       0.43      0.54      0.48       476\n",
      "\n",
      "    accuracy                           0.37      2000\n",
      "   macro avg       0.29      0.33      0.31      2000\n",
      "weighted avg       0.33      0.37      0.34      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[115   0 103  37  40]\n",
      " [ 64   0  81  28  25]\n",
      " [ 80   0 183 147  98]\n",
      " [ 60   0 107 177 179]\n",
      " [ 28   0  76 115 257]]\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [01:02<00:00, 17.97it/s, loss=0.0882, acc=0.378]\n",
      "100%|██████████| 125/125 [00:02<00:00, 50.81it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.37       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.36      0.43      0.39       508\n",
      "           3       0.36      0.36      0.36       523\n",
      "           4       0.43      0.56      0.49       476\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.31      0.34      0.32      2000\n",
      "weighted avg       0.35      0.39      0.36      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 99   0 111  36  49]\n",
      " [ 52   0  87  29  30]\n",
      " [ 46   0 219 146  97]\n",
      " [ 32   0 126 188 177]\n",
      " [ 18   0  73 118 267]]\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [01:09<00:00, 16.30it/s, loss=0.0869, acc=0.392]\n",
      "100%|██████████| 125/125 [00:02<00:00, 50.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.42      0.39       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.35      0.55      0.43       508\n",
      "           3       0.41      0.21      0.28       523\n",
      "           4       0.43      0.55      0.49       476\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.31      0.35      0.32      2000\n",
      "weighted avg       0.35      0.39      0.35      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[123   0 117  11  44]\n",
      " [ 62   0 107   5  24]\n",
      " [ 65   2 279  69  93]\n",
      " [ 56   0 177 109 181]\n",
      " [ 31   0 108  74 263]]\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [01:01<00:00, 18.37it/s, loss=0.0856, acc=0.404]\n",
      "100%|██████████| 125/125 [00:02<00:00, 50.52it/s]\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/him/anaconda3/envs/COMP4332_Project/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.34      0.53      0.42       508\n",
      "           3       0.37      0.26      0.31       523\n",
      "           4       0.45      0.59      0.51       476\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.32      0.34      0.32      2000\n",
      "weighted avg       0.36      0.39      0.36      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 97   0 129  23  46]\n",
      " [ 47   0 107  18  26]\n",
      " [ 38   0 267 113  90]\n",
      " [ 23   0 177 138 185]\n",
      " [ 15   0  98  80 283]]\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:44<00:00, 25.22it/s, loss=0.0843, acc=0.417]\n",
      "100%|██████████| 125/125 [00:02<00:00, 52.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.42      0.42       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.33      0.37      0.35       508\n",
      "           3       0.36      0.40      0.38       523\n",
      "           4       0.47      0.55      0.51       476\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.32      0.35      0.33      2000\n",
      "weighted avg       0.35      0.39      0.37      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[125   0  98  39  33]\n",
      " [ 62   0  84  31  21]\n",
      " [ 61   2 186 176  83]\n",
      " [ 30   0 125 208 160]\n",
      " [ 25   2  65 122 262]]\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:48<00:00, 23.22it/s, loss=0.0836, acc=0.421]\n",
      "100%|██████████| 125/125 [00:01<00:00, 100.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.33      0.37       295\n",
      "           1       0.14      0.01      0.01       198\n",
      "           2       0.36      0.47      0.40       508\n",
      "           3       0.39      0.42      0.40       523\n",
      "           4       0.51      0.57      0.54       476\n",
      "\n",
      "    accuracy                           0.41      2000\n",
      "   macro avg       0.36      0.36      0.34      2000\n",
      "weighted avg       0.39      0.41      0.39      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 97   4 121  38  35]\n",
      " [ 48   1 107  30  12]\n",
      " [ 41   1 238 159  69]\n",
      " [ 24   1 132 218 148]\n",
      " [ 16   0  72 117 271]]\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:52<00:00, 21.62it/s, loss=0.0825, acc=0.428]\n",
      "100%|██████████| 125/125 [00:02<00:00, 54.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.44      0.41       295\n",
      "           1       0.15      0.01      0.02       198\n",
      "           2       0.38      0.40      0.39       508\n",
      "           3       0.41      0.29      0.34       523\n",
      "           4       0.44      0.70      0.54       476\n",
      "\n",
      "    accuracy                           0.41      2000\n",
      "   macro avg       0.35      0.37      0.34      2000\n",
      "weighted avg       0.38      0.41      0.38      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[130   4  87  19  55]\n",
      " [ 71   2  72  18  35]\n",
      " [ 64   4 202 117 121]\n",
      " [ 39   2 119 150 213]\n",
      " [ 30   1  47  66 332]]\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:58<00:00, 19.37it/s, loss=0.0818, acc=0.435]\n",
      "100%|██████████| 125/125 [00:02<00:00, 48.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.43      0.42       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.40      0.32      0.35       508\n",
      "           3       0.38      0.36      0.37       523\n",
      "           4       0.43      0.71      0.53       476\n",
      "\n",
      "    accuracy                           0.41      2000\n",
      "   macro avg       0.33      0.36      0.34      2000\n",
      "weighted avg       0.36      0.41      0.38      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[126   3  67  33  66]\n",
      " [ 71   0  61  28  38]\n",
      " [ 53   2 162 168 123]\n",
      " [ 30   0  78 190 225]\n",
      " [ 19   0  37  83 337]]\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:48<00:00, 23.40it/s, loss=0.081, acc=0.444] \n",
      "100%|██████████| 125/125 [00:01<00:00, 101.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.40      0.43       295\n",
      "           1       0.27      0.02      0.03       198\n",
      "           2       0.37      0.51      0.43       508\n",
      "           3       0.40      0.35      0.37       523\n",
      "           4       0.48      0.58      0.52       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.40      0.37      0.36      2000\n",
      "weighted avg       0.41      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[119   3 107  20  46]\n",
      " [ 51   3  97  32  15]\n",
      " [ 55   5 257 114  77]\n",
      " [ 23   0 155 183 162]\n",
      " [ 11   0  85 105 275]]\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 45.85it/s, loss=0.0803, acc=0.444]\n",
      "100%|██████████| 125/125 [00:01<00:00, 118.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.48      0.44       295\n",
      "           1       0.30      0.06      0.09       198\n",
      "           2       0.40      0.34      0.37       508\n",
      "           3       0.39      0.35      0.37       523\n",
      "           4       0.44      0.64      0.52       476\n",
      "\n",
      "    accuracy                           0.41      2000\n",
      "   macro avg       0.38      0.37      0.36      2000\n",
      "weighted avg       0.39      0.41      0.39      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[143  16  56  25  55]\n",
      " [ 76  11  57  24  30]\n",
      " [ 76   9 173 144 106]\n",
      " [ 39   1  98 181 204]\n",
      " [ 27   0  48  94 307]]\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 46.18it/s, loss=0.0799, acc=0.451]\n",
      "100%|██████████| 125/125 [00:01<00:00, 117.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44       295\n",
      "           1       0.44      0.04      0.07       198\n",
      "           2       0.38      0.47      0.42       508\n",
      "           3       0.39      0.34      0.36       523\n",
      "           4       0.46      0.64      0.54       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.43      0.38      0.37      2000\n",
      "weighted avg       0.43      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[119   6  96  29  45]\n",
      " [ 52   8  87  26  25]\n",
      " [ 46   3 240 131  88]\n",
      " [ 20   0 134 177 192]\n",
      " [  8   1  78  86 303]]\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:33<00:00, 33.35it/s, loss=0.0791, acc=0.459]\n",
      "100%|██████████| 125/125 [00:01<00:00, 85.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.45       295\n",
      "           1       0.35      0.03      0.06       198\n",
      "           2       0.39      0.46      0.42       508\n",
      "           3       0.37      0.33      0.35       523\n",
      "           4       0.48      0.62      0.54       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.41      0.38      0.36      2000\n",
      "weighted avg       0.41      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[134   7  88  25  41]\n",
      " [ 61   6  80  31  20]\n",
      " [ 53   3 234 136  82]\n",
      " [ 36   1 141 172 173]\n",
      " [ 21   0  64  96 295]]\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 45.01it/s, loss=0.0786, acc=0.461]\n",
      "100%|██████████| 125/125 [00:01<00:00, 115.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.35      0.40       295\n",
      "           1       0.33      0.05      0.09       198\n",
      "           2       0.37      0.49      0.43       508\n",
      "           3       0.40      0.30      0.34       523\n",
      "           4       0.47      0.68      0.56       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.41      0.38      0.36      2000\n",
      "weighted avg       0.41      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[104  12 105  23  51]\n",
      " [ 46  10  94  22  26]\n",
      " [ 39   5 251 118  95]\n",
      " [ 18   2 156 155 192]\n",
      " [ 14   1  67  69 325]]\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:26<00:00, 43.09it/s, loss=0.0778, acc=0.469]\n",
      "100%|██████████| 125/125 [00:01<00:00, 114.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44       295\n",
      "           1       0.32      0.04      0.07       198\n",
      "           2       0.36      0.46      0.41       508\n",
      "           3       0.40      0.34      0.37       523\n",
      "           4       0.49      0.61      0.55       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.40      0.38      0.37      2000\n",
      "weighted avg       0.41      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[131   7  94  27  36]\n",
      " [ 55   8  90  20  25]\n",
      " [ 60   8 236 128  76]\n",
      " [ 31   0 155 179 158]\n",
      " [ 19   2  72  94 289]]\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 45.55it/s, loss=0.0772, acc=0.472]\n",
      "100%|██████████| 125/125 [00:01<00:00, 115.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44       295\n",
      "           1       0.36      0.06      0.10       198\n",
      "           2       0.38      0.47      0.42       508\n",
      "           3       0.39      0.38      0.38       523\n",
      "           4       0.50      0.60      0.55       476\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.42      0.39      0.38      2000\n",
      "weighted avg       0.42      0.43      0.41      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[126  11  84  37  37]\n",
      " [ 54  12  87  28  17]\n",
      " [ 49   7 240 140  72]\n",
      " [ 27   2 144 197 153]\n",
      " [ 16   1  72 103 284]]\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 46.11it/s, loss=0.0767, acc=0.474]\n",
      "100%|██████████| 125/125 [00:01<00:00, 120.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.51      0.46       295\n",
      "           1       0.23      0.10      0.14       198\n",
      "           2       0.36      0.40      0.38       508\n",
      "           3       0.39      0.35      0.37       523\n",
      "           4       0.51      0.59      0.55       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.39      0.39      0.38      2000\n",
      "weighted avg       0.40      0.42      0.41      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[149  18  73  24  31]\n",
      " [ 63  19  74  27  15]\n",
      " [ 72  26 204 135  71]\n",
      " [ 36  13 141 183 150]\n",
      " [ 26   5  69  97 279]]\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 44.13it/s, loss=0.0761, acc=0.477]\n",
      "100%|██████████| 125/125 [00:01<00:00, 111.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.46       295\n",
      "           1       0.32      0.07      0.11       198\n",
      "           2       0.39      0.43      0.41       508\n",
      "           3       0.39      0.33      0.36       523\n",
      "           4       0.48      0.64      0.55       476\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.40      0.39      0.38      2000\n",
      "weighted avg       0.41      0.43      0.41      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[144  11  71  31  38]\n",
      " [ 60  13  79  26  20]\n",
      " [ 66  11 216 123  92]\n",
      " [ 33   4 135 175 176]\n",
      " [ 22   2  56  91 305]]\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 43.98it/s, loss=0.0756, acc=0.487]\n",
      "100%|██████████| 125/125 [00:01<00:00, 108.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.38      0.43       295\n",
      "           1       0.27      0.06      0.10       198\n",
      "           2       0.37      0.44      0.40       508\n",
      "           3       0.37      0.35      0.36       523\n",
      "           4       0.47      0.62      0.53       476\n",
      "\n",
      "    accuracy                           0.41      2000\n",
      "   macro avg       0.39      0.37      0.36      2000\n",
      "weighted avg       0.40      0.41      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[112  16  90  33  44]\n",
      " [ 42  12  91  33  20]\n",
      " [ 48   9 226 136  89]\n",
      " [ 16   5 141 181 180]\n",
      " [ 11   2  61 107 295]]\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:26<00:00, 43.15it/s, loss=0.0751, acc=0.488]\n",
      "100%|██████████| 125/125 [00:01<00:00, 113.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46       295\n",
      "           1       0.25      0.04      0.07       198\n",
      "           2       0.37      0.46      0.41       508\n",
      "           3       0.39      0.36      0.37       523\n",
      "           4       0.50      0.58      0.54       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.39      0.38      0.37      2000\n",
      "weighted avg       0.41      0.42      0.41      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[134   8  85  31  37]\n",
      " [ 59   8  84  29  18]\n",
      " [ 54  10 236 134  74]\n",
      " [ 26   6 155 189 147]\n",
      " [ 15   0  79 104 278]]\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:24<00:00, 45.56it/s, loss=0.0746, acc=0.497]\n",
      "100%|██████████| 125/125 [00:01<00:00, 116.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46       295\n",
      "           1       0.25      0.07      0.10       198\n",
      "           2       0.38      0.44      0.41       508\n",
      "           3       0.40      0.29      0.34       523\n",
      "           4       0.48      0.68      0.56       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.39      0.39      0.37      2000\n",
      "weighted avg       0.41      0.42      0.40      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[141  14  77  20  43]\n",
      " [ 62  13  75  24  24]\n",
      " [ 66  15 222 113  92]\n",
      " [ 32   6 148 152 185]\n",
      " [ 20   3  63  68 322]]\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:30<00:00, 36.55it/s, loss=0.0741, acc=0.497]\n",
      "100%|██████████| 125/125 [00:01<00:00, 116.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46       295\n",
      "           1       0.38      0.09      0.15       198\n",
      "           2       0.35      0.39      0.37       508\n",
      "           3       0.38      0.36      0.37       523\n",
      "           4       0.50      0.65      0.56       476\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.42      0.39      0.38      2000\n",
      "weighted avg       0.41      0.42      0.41      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[134  10  79  32  40]\n",
      " [ 55  18  78  29  18]\n",
      " [ 57  13 197 151  90]\n",
      " [ 25   5 142 187 164]\n",
      " [ 16   2  59  91 308]]\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:33<00:00, 33.74it/s, loss=0.0735, acc=0.499]\n",
      "100%|██████████| 125/125 [00:01<00:00, 111.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44       295\n",
      "           1       0.31      0.13      0.18       198\n",
      "           2       0.36      0.40      0.38       508\n",
      "           3       0.39      0.43      0.41       523\n",
      "           4       0.52      0.59      0.55       476\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.42      0.39      0.39      2000\n",
      "weighted avg       0.42      0.43      0.42      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[119  26  78  36  36]\n",
      " [ 45  25  80  30  18]\n",
      " [ 45  19 201 171  72]\n",
      " [ 22   7 133 227 134]\n",
      " [ 11   3  68 112 282]]\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 44.49it/s, loss=0.073, acc=0.503] \n",
      "100%|██████████| 125/125 [00:01<00:00, 121.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.52      0.46       295\n",
      "           1       0.31      0.08      0.13       198\n",
      "           2       0.41      0.37      0.39       508\n",
      "           3       0.38      0.41      0.40       523\n",
      "           4       0.52      0.60      0.56       476\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.41      0.40      0.39      2000\n",
      "weighted avg       0.42      0.43      0.42      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[153  17  52  41  32]\n",
      " [ 69  16  63  33  17]\n",
      " [ 78  13 188 156  73]\n",
      " [ 43   4 115 217 144]\n",
      " [ 24   2  44 119 287]]\n",
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:25<00:00, 44.00it/s, loss=0.0727, acc=0.511]\n",
      "100%|██████████| 125/125 [00:01<00:00, 97.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.46      0.46       295\n",
      "           1       0.30      0.16      0.20       198\n",
      "           2       0.39      0.41      0.40       508\n",
      "           3       0.39      0.33      0.36       523\n",
      "           4       0.50      0.66      0.56       476\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.41      0.40      0.40      2000\n",
      "weighted avg       0.42      0.43      0.42      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[137  27  64  27  40]\n",
      " [ 56  31  65  24  22]\n",
      " [ 61  30 207 124  86]\n",
      " [ 26  12 143 173 169]\n",
      " [ 21   5  48  90 312]]\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, 31):    \n",
    "    print('epoch', e)\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with tqdm.tqdm(train_loader) as t:\n",
    "        for x, y in t:\n",
    "            # print(x.shape)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with tqdm.tqdm(valid_loader) as t:\n",
    "        for x, y in t:\n",
    "            logits = model(x)\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += len(y)\n",
    "            y_pred += logits.argmax(1).tolist()\n",
    "            y_true += y.tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('COMP4332_Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cfe628363714e2cc319f5f9909ac20c6e4768ce99385b26bf0600af3158fd82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
